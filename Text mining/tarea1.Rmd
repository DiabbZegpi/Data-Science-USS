---
title: "Tarea 1"
author: "Diabb Zegpi"
date: "25-12-2021"
output: 
  html_document:
    theme: united
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
ragg_png = function(..., res = 500) {
  ragg::agg_png(..., res = res, units = "in")
}

knitr::opts_chunk$set(
  echo = TRUE, 
  class.output = "purple-output",
  dev = "ragg_png", 
  fig.align = "center"
)
```

<style>
  body {
    font-size: 16px;
    background-color: #fff9fa;
  }
  
  pre {
    border: 0px;
  }

  .sourceCode, code {
    font-family: 'Fira Mono';
  }
  
  code {
    background-color: #e5eeeb;
    color: #111;
  }
  
  pre.sourceCode {
    color: #111;
    font-weight: 500;
    background-color: #e5eeeb;
  }
  
  code span.fu {
    color: #0e4747;
    font-weight: 600;
  }
  
  code span.sc {
    color: #ae4d00;
    font-weight: 600;
  }
  
  code span.st {
    color: #ae4d00;
  }
  
  .purple-output{
    background-color: #012626;
    color: #eee;
  }
</style>


Este trabajo consiste en la utilización del chat del grupo de Whatsapp *"Magíster USS"*, grupo que conformamos todos los compañeros del Magíster en Data Science, generación 2020. Cabe aclarar que cuento con el consentimiento de mis compañeros para utilizar estos datos, razón por la que tendré los los resguardos necesarios para no exponer conversaciones privadas o comprometedoras. Todos los mensajes fueron enviados en el período correspondido entre el 11 de junio y el 11 de noviembre de 2021.

El objetivo del proyecto es utilizar los datos de mensajes del grupo para predecir quién es autor(a) de un mensaje determinado.

Primero que todo, se cargan los paquetes de funciones a utilizar en el análisis.

```{r warning=FALSE, message=FALSE}
# Dependencias
library(tidyverse)
library(tidymodels)
library(textrecipes)
library(tidytext)
library(spacyr)
library(here)
library(stringi)
library(lubridate)
tidymodels_prefer()
```

Después, se importa el archivo con extensión *.txt* con los datos de conversaciones del grupo. Estos datos son una lista, en que cada nueva línea se compone por un mensaje nuevo o por un salto de línea dentro dentro de un mensaje. Cada mensaje tiene el formato *6/11/2021 20:34 - Remitente: mensaje*. Este formato no es ideal para el análisis de datos, por esto, se recorre la lista de mensajes y saltos de líneas para formar un dataset con 3 columnas: `sender`, `datetime` y `message`.

```{r warning=FALSE}
text <- read.delim(here("Text Mining", "chat_wsp.txt"), 
                   encoding = "UTF-8",
                   sep = "\n",
                   col.names = "text",
                   skip = 1) %>% 
  as_tibble()


text <- text$text
datetime_regex <- "^\\d{1,2}/\\d{1,2}/\\d{4} \\d{2}:\\d{2}"
j <- 1
sender <- vector("character")
datetime <- vector("character")
message <- vector("character")

for (i in 1:length(text)) {
  if (str_detect(text[i], datetime_regex)) {
    sender[j] <- str_match(text[i], "^.+ - (.+?): ")[,2] 
    datetime[j] <- str_match(text[i], datetime_regex)[,1]
    message[j] <- str_match(text[i], "^.+: (.+)$")[,2]
    j <- j + 1
  } else {
    message[j] <- paste(message[j], text[i], sep = " ")
  }
}

chat <- tibble(
  sender = sender, 
  datetime = datetime,
  message = message
)

head(chat)
```

El largo del dataset es de `r nrow(chat)` mensajes. Ha de notarse que muchos de ellos son contenido multimedia, sean como imágenes, audios o videos. Debido a que el análisis del contenido multimedia está fuera del alcance del proyecto, estos han sido omitidos, por ende, los mensajes de multimedia tienen que ser excluidos.

Otra característica del dataset es la codificación: hay caracteres con tildes y emoticones, los que serán removidos en pos de simplificar el análisis. El costo de esta operación es que el texto perderá interpretabilidad, debido a la remoción de tildes y de la letra *ñ*. 

Como etapas finales de la preparación de datos, el texto se pasa a minúsculas y se quitan todos los caracteres que no sean letras del alfabeto latino. Adicionalmente, para mejorar el poder predictivo de los modelos posteriores, se crean las columnas `hour` y `week_day`.

```{r}
chat_clean <- chat %>% 
  mutate(message = stri_trans_general(message, id = "Latin-ASCII"),
         message = str_replace_all(message, "[^\x01-\x7F]", ""),
         message = str_replace(message, "<Multimedia omitido>", ""),
         message = str_to_lower(message),
         message = str_replace_all(message, "[^a-z]", " "),
         message = str_replace_all(message, "\\s+", " "),
         date = as_date(str_sub(datetime, end = -7L), format = "%d/%m/%Y"),
         hour = as.numeric(str_sub(datetime, start = -5L, end = -4L)),
         week_day = wday(date, week_start = 1)) %>% 
  select(-c(datetime, date)) %>% 
  filter(!is.na(message) & str_length(message) > 0)
```

El dataset resultante tiene `r ncol(chat_clean)` variables y `r nrow(chat_clean)` filas o mensajes, sin datos faltantes. 

```{r}
head(chat_clean) 
```


## Partición en train y test

Previo a continuar el análisis exploratorio, se separará el dataset en conjuntos de training y testing, usando muestreo estratificado de acuerdo con el target (sender) y en proporciones 80 y 20%, respectivamente. Para tener una mejor estimación de la precisión de los modelos, podría usarse k-fold cross-validation, pero será obviado por las condiciones de hardware del equipo en que se trabaja.

```{r}
set.seed(123)
chat_split <- initial_split(chat_clean, prop = .8, strata = sender)
chat_train <- training(chat_split)
chat_test <- testing(chat_split)
```

## Exploración de mensajes

```{r echo=FALSE}
library(ggtext)
theme_set(theme_light(base_family = "Segoe UI", base_size = 16))
theme_update(
  plot.background = element_rect(fill = "#fff9fa", color = "transparent"),
  panel.background = element_rect(fill = "#eeeeee"),
  text = element_text(color = "#111111"),
  plot.title = element_markdown(hjust = .5),
  plot.subtitle = element_markdown(hjust = .5),
  strip.background = element_rect(fill = "#fff9fa"),
  strip.text = element_text(color = "#111111", face = "italic", size = "16")
)
```

Se continuará con la exploración de la variable objetivo: sender. Un modelo clasificador tenderá a clasificar mejor la clase de la que vea más ejemplos. Por ello, es importante nivelar las clases para mejorar el rendimiento de los modelos subsecuentes.

```{r echo=FALSE}
sender_counts <- chat_train %>% 
  count(sender) 

xintercept <- round(mean(sender_counts$n))

sender_counts %>% 
  mutate(sender = fct_reorder(sender, n)) %>% 
  ggplot(aes(n, sender)) +
  geom_col(alpha = .8) +
  geom_vline(aes(xintercept = mean(n)), lty = 2) +
  annotate("text", label = paste("mu == ", xintercept),
           x = xintercept + 20, y = 5, parse = TRUE) +
  labs(x = "# de mensajes", y = NULL, 
       title = "¿Quiénes son más activos en WhatsApp?")
```

En el conjunto de entrenamiento, solamente 4 personas, entre junio y diciembre de 2021, superaron la marca de 100 mensajes enviados. Entre estas 4 personas acumulan 613 mensajes, en otras palabras, enviaron el 59,7% de los mensajes durante el período de estudio.

La media de mensajes enviados es igual a `r xintercept`. Para los efectos del modelo de clasificación, se conservarán las etiquetas de las 6 personas más activas, porque tienen más de 80 mensajes, agrupando los 7 restantes en una sola categoría. 

```{r}
sender_target <- chat_train %>% 
  count(sender) %>% 
  filter(n > 80) %>% 
  pull(sender)

chat_train <- chat_train %>% 
  mutate(sender = if_else(sender %in% sender_target,
                          sender,
                          "Otro"),
         sender = factor(sender))

chat_test <- chat_test %>% 
  mutate(sender = if_else(sender %in% sender_target,
                          sender,
                          "Otro"),
         sender = factor(sender))
```


```{r echo=FALSE}
sender_counts %>% 
  arrange(desc(n)) %>% 
  mutate(cumsum = cumsum(n),
         pct = cumsum / sum(cumsum))  
```

Otro asunto relevante es el comportamiento de los mensajes de acuerdo a la hora del día. Esto se explorará con diagramas de cajas.

```{r echo=FALSE}
chat_train %>% 
  mutate(sender = as.character(sender),
         sender = if_else(str_detect(sender, "\\s"),
                          str_match(sender, "^(.+)\\s.*")[,2],
                          sender)) %>%
  ggplot(aes(reorder(sender, hour), hour)) +
  geom_boxplot() +
  labs(x = NULL, y = "Hora del día",
       title = "Mensajeros diurnos y nocturnos") +
  scale_y_continuous(breaks = seq(0, 24, 6),
                     labels = seq(0, 24, 6)) +
  theme(axis.text.x = element_text(angle = 90))
```

En el gráfico anterior se observan diferencias en los patrones de envío de mensajes de acuerdo a la hora del día: Danilo saluda todos los días entre las 6 y las 7 de la mañana; Álvaro es activo durante todo el día, pero el 50% de su actividad es entre las 10 de la mañana y las 8 de la tarde, muy parecido a Miguel y José Luis; Marcela tiene mucha actividad en torno a las 13 horas, con desviaciones hasta las 23, etc.

Por último, se explora el día de la semana como factor predictivo para el envío de mensajes.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(ggridges)
chat_train %>% 
  mutate(sender = as.character(sender),
         sender = if_else(str_detect(sender, "\\s"),
                          str_match(sender, "^(.+)\\s.*")[,2],
                          sender)) %>% 
  ggplot(aes(y = reorder(sender, week_day), x = week_day)) +
  stat_binline(bins = 7, binwidth = .5, scale = 1.5) +
  labs(x = NULL, y = NULL,
       title = "Mensajes por día de la semana") +
  scale_x_continuous(breaks = 1:7,
                     labels = c(
                       "lunes", "martes", "miércoles", "jueves", "viernes", "sábado", "domingo"
                     )) 
```

Aparentemente, más característico que el día de la semana para discriminar entre mis compañeros, es saber si ese día es martes-miércoles o lunes-jueves-viernes-sábado, porque en domingo es muy baja la frecuencia de mensajes. Aún así, se mantendrán los días de la semana, sin transformar.

## Procesamiento de texto

A continuación, se especifica una secuencia de preprocesamiento, que posteriormente puede ser usada por los modelos. Estas etapas de preprocesamiento son:

1. Tokenizar los mensajes.
2. Excluir las stopwords en español de la lista SnowballC.
3. Lematizar con spaCy.
4. Filtrar a los 250 tokens más frecuentes.
5. Calcular tf-idf.

```{r message=FALSE, warning=FALSE}
spacy_initialize(model = "es_core_news_sm")

text_recipe <- recipe(sender ~ ., data = chat_train) %>% 
  step_tokenize(message, engine = "spacyr") %>% 
  step_stopwords(message, language = "es") %>%
  step_lemma(message) %>% 
  step_tokenfilter(message, max_tokens = 250) %>% 
  step_tfidf(message) 
```

A continuación, se crean las especificaciones de modelos multiclase: un clasificador bayesiano y un modelmultinomial con regularización L2, de la familia de los modelos lineales generalizados.

```{r}
library(discrim)
bayes_spec <- naive_Bayes() %>% 
  set_mode("classification") %>% 
  set_engine("naivebayes")

multinom_spec <- multinom_reg(penalty = .001, mixture = 1) %>%
  set_mode("classification") %>% 
  set_engine("glmnet")
```

Posteriormente, se forma un workflow para cada modelo especificado, con el fin de organizar el entrenamiento y obtener predicciones con mayor sencillez.

```{r}
bayes_wf <- workflow() %>% 
  add_recipe(text_recipe) %>% 
  add_model(bayes_spec)

multinom_wf <- workflow() %>% 
  add_recipe(text_recipe) %>% 
  add_model(multinom_spec)
```

Ahora, se ajustan los modelos en el conjunto de entrenamiento.

```{r message=FALSE, warning=FALSE}
bayes_fit <- fit(bayes_wf, data = chat_train)
multinom_fit <- fit(multinom_wf, data = chat_train)

bayes_train_pred <- predict(bayes_fit, chat_train)
multinom_train_pred <- predict(multinom_fit, chat_train)
```

A continuación, se evalúan los modelos en el conjunto de entrenamiento.

```{r}
chat_train %>% 
  bind_cols(bayes_train_pred) %>% 
  accuracy(truth = sender, .pred_class)
```

Por lo visto, el modelo bayesiano tiene un accuracy muy pobre, pero equivalente al accuracy esperado del modelo nulo. Esto indica que el estimador bayesiano solamente predice la clase más frecuente, que es "Otro". Por ende, no se consiguió el aprendizaje.

```{r}
chat_train %>% 
  bind_cols(multinom_train_pred) %>% 
  accuracy(truth = sender, .pred_class)
```

Por otra parte, el modelo multinomial supera ampliamente al bayesiano, pero no supera un desempeño moderado. Al examinar el ajuste de este modelo se puede identificar a las variables con mayor influencia sobre la predicción.

```{r echo=FALSE}
multinom_fit %>% 
  tidy() %>% 
  mutate(term = str_remove(term, "tfidf_message_"),
         term = str_remove(term, " ")) %>% 
  filter(str_length(term) > 0, term != "(Intercept)") %>% 
  group_by(class) %>% 
  slice_max(abs(estimate), n = 10, with_ties = FALSE) %>% 
  ungroup() %>% 
  mutate(term = reorder_within(term, estimate, class)) %>% 
  ggplot(aes(estimate, term, fill = estimate > 0)) +
  geom_col(show.legend = FALSE, alpha = .8) +
  scale_y_reordered() +
  scale_fill_manual(values = c("tomato", "deepskyblue3")) +
  labs(x = expression(beta), y = NULL) +
  facet_wrap(~class, scales = "free_y")
```

Se observa que los mensajes de José Luis y Miguel están relacionados con código y tareas; Marcela también habla de tareas y de pedir más tiempo para entregar; los mensajes de Danilo son saludos matutinos; mucho se habla de classroom y Álvaro se caracteriza por hablar de sitios web, indicando que facilita los enlaces para entrar en las clases; el grupo "Otro" habla de crimen, debido a que en el período trabajamos con datos de crímenes en Estados Unidos.

## Evaluación en conjunto de testing y prueba

```{r message=FALSE, warning=FALSE}
multinom_test_pred <- predict(multinom_fit, new_data = chat_test)
chat_test %>% 
  bind_cols(multinom_test_pred) %>% 
  accuracy(truth = sender, .pred_class)
```

En la prueba, el modelo multinomial tiene mucho peor desempeño que en el entrenamiento, dando una clara señal de sobreajuste.

```{r}
chat_test %>% 
  bind_cols(multinom_test_pred) %>% 
  conf_mat(truth = sender, .pred_class) 
```

La matriz de confusión demuestra que la clase "Otro" se superpone con todas las demás, porque el modelo no logra discriminar entre nuestros mensajes, dado que hablamos todos sobre tópicos del magíster.

```{r}
testing_phrases <- tibble(
  message = c("Buenos días muchachada", "Danilo san", "Podríamos pedir más plazo para entregar la tarea", "Para cuándo quedó el asado?"),
  hour = c(7, 14, 23, 19),
  week_day = c(1, 4, 6, 5)
)

predict(multinom_fit, new_data = testing_phrases)
```

Pese al bajo accuracy del modelo, la predicción de estas 4 frases es satisfactoria. Por lo menos, se han identificado ciertos estilos y tópicos.

## Conclusiones

Hay dos enfoques para mejorar el modelo de predicción multiclase:

1. **data-centric**: conseguir más datos, mejorar la limpieza e incluir diccionarios, generar texto sintético para aumentar la muestra de las clases menos representadas, incluir emojis en el análisis, considerar la creación de la variable "fin de semana" y su interacción con las palabras tarea, clase y link, reescalar los datos, utilizar una lista de stopwords personalizada.
2. **algorithm-centric**: utilizar algoritmos basados en ensemble y boosting, cambiar el kernel del estimador bayesiano, utilizar model stacking, cambiar la configuración de regularización con grid search, cambiar el lematizador, evaluar con ROC AUC en lugar de accuracy, crear modelos escalonados para resolver el caso binario, después el de 3 niveles y así sucesivamente.



























