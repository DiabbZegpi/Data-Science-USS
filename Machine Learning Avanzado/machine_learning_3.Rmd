---
title: "Taller 3 de Machine Learning Avanzado"
author: 
  - Araneda F., Marcela
  - Reyes G., Álvaro
  - Sepúlveda M., Danilo
  - Zegpi D., Diabb
output: 
  html_document:
    theme: united
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
ragg_png = function(..., res = 500) {
  ragg::agg_png(..., res = res, units = "in")
}

knitr::opts_chunk$set(
  echo = TRUE, 
  class.output = "purple-output",
  dev = "ragg_png", 
  fig.align = "center"
)
```

<style>
  body {
    font-size: 16px;
    background-color: #fff9fa;
  }
  
  pre {
    border: 0px;
  }

  .sourceCode, code {
    font-family: 'Fira Mono';
  }
  
  code {
    background-color: #e5eeeb;
    color: #111;
  }
  
  pre.sourceCode {
    color: #111;
    font-weight: 500;
    background-color: #e5eeeb;
  }
  
  code span.fu {
    color: #0e4747;
    font-weight: 600;
  }
  
  code span.sc {
    color: #ae4d00;
    font-weight: 600;
  }
  
  code span.st {
    color: #ae4d00;
  }
  
  .purple-output{
    background-color: #012626;
    color: #eee;
  }
</style>


```{r warning=FALSE, message=FALSE}
# Dependencias 
# install.packages(c("tidyverse", "tidymodels","here", "janitor", reticulate", "keras"))

library(tidyverse)
library(tidymodels)
library(here)
startup_raw <- read_csv(file = here("Machine Learning Avanzado", "startup data.csv")) %>% 
  janitor::clean_names()
```


```{r echo=FALSE}
library(ggtext)
theme_set(theme_light(base_family = "Segoe UI", base_size = 16))
theme_update(
  plot.background = element_rect(fill = "#fff9fa", color = "transparent"),
  panel.background = element_rect(fill = "#eeeeee"),
  text = element_text(color = "#111111"),
  plot.title = element_markdown(hjust = .5),
  plot.subtitle = element_markdown(hjust = .5),
  strip.background = element_rect(fill = "#fff9fa"),
  strip.text = element_text(color = "#111111", face = "italic", size = "16")
)
```


El dataset `startup` registra información de empresas emergentes (startups) en Estados Unidos. En total, contiene 923 filas y 49 columnas. Cada fila representa a una startup y cada columna a una característica de ésta. Inicialmente, hay muchas columnas que pueden ser construidos a partir de éstas, causando así duplicidad de datos. Por tanto, el primer análisis consistirá en determinar cuáles columnas pueden ser excluidas del dataset sin perder información relevante.

Las variables dummy a descartar serán reconstruidas en el proceso de modelamiento, pero, por el momento, serán excluidas.


```{r}
startup <- startup_raw %>% 
  select(-c(unnamed_0, zip_code, id, unnamed_6, labels, closed_at, state_code_1, object_id),
         -starts_with("is_")) 

colnames(startup)
```


El dataset resultante tiene `ncol(startup)` columnas, `select(startup, where(is.character)) %>% ncol()` de las cuales son categóricas y las demás son numéricas. De las columnas categóricas, 3 corresponden a fechas, por lo que se procede a adaptarlas.


```{r}
startup <- startup %>% 
  mutate(across(
    matches("fo?und") & where(is.character),
    function(x) as.Date(x, format = "%m/%d/%Y")            
  )) 
```


A continuación, se exploran descriptivamente todas las variables, de acuerdo con us tipo de dato.

### Variables categóricas
- No hay *missing data* en las columnas categóricas. 
- Las empresas provienen de 35 estados; el 52,9% es de California (CA).
- En total son 221 ciudades. San Francisco tiene la primera mayoría (13,9%).
- Las startups se dedican a 35 rubros. Las dos grandes mayorías son software (16,6%) y web (15,6%).
- Existe desequilibrio entre las dos clases de la variable objetivo `status`: acquired (64,7%) y closed (35,3%).
- Las columnas `has_` *vc*, *angel*, *round_{a, b, c, d}* son variables dummy no mutuamente excluyentes.


### Variables fecha
- Las empresas fueron fundadas entre el 1 de enero de 1984 y el 16 de abirl de 2013.
- Todas las empresas obtuvieron su primer financiamiento entre enero del 2000 y noviembre del 2013.
- Todas las empresas obtuvieron su último financiamiento entre enero del 2001 y noviembre del 2013.


## Variables numéricas
- La antigüedad de la empresa hasta su primer y último


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(maps)
main_states <- map_data("state")
ggplot() +
  geom_polygon(data = main_states, aes(long, lat, group = group),
               fill = "#012626", color = "white", size = .1) +
  geom_point(data = startup, aes(longitude, latitude),
             inherit.aes = FALSE, fill = "gold3", size = 5, 
             alpha = .4, shape = 21, color = "gray30", stroke = 1) +
  coord_cartesian(xlim = c(-125, -69), ylim = c(25, 50)) +
  theme_void()
```


El mapa superior muestra las empresas registradas en USA. Solamente hay 4 empresas fuera de USA: Xelerated en el Mar Arábigo (Sureste de Omán), Moli, DiJiPOP y Tracelytics, las tres en el Océano Índico, al Este de Somalia. Por supuesto, las cuatro empresas se encuentran adscritas a ciudades estadounidenses, por lo que sus coordenadas son susceptibles a imputación. Las demás variables numéricas se describen a continuación:

- Los rangos de las variables de antigüedad de las empresas hasta su primer o último financiamiento e hito incluyen números negativos. Esto se interpreta como factible.
- La antigüedad de las empresas hasta su primer y último hito tiene missing data. Se detecta dependencia entre estas variables y el *status* de las empresas.
- Las correlaciones entre las variables numéricas se muestran en la matriz de correlación.


```{r echo=FALSE, warning=FALSE, message=FALSE}
corm <-
  startup %>%
  select(where(is.numeric), -starts_with("has_"), -milestones) %>%
  corrr::correlate(diagonal = 1) %>%
  corrr::shave(upper = FALSE)

corm <- corm %>%
  pivot_longer(
    cols = -term,
    names_to = "colname",
    values_to = "corr"
  ) %>%
  mutate(rowname = fct_inorder(term),
         colname = fct_inorder(colname))

corr_labs <- unique(corm$rowname)

ggplot(corm, aes(rowname, fct_rev(colname), fill = corr)) +
  geom_tile(size = 2) +
  geom_text(aes(
    label = format(round(corr, 2), nsmall = 2),
    color = abs(corr) < .4
  )) +
  scale_color_manual(values = c("white", "black"), 
                     guide = "none", na.value = "#fff9fa") +
  scale_fill_gradient2(
    low = "#e5eeeb", mid = "#e5eeeb", high = "#012626", na.value = "#fff9fa",
    limits = c(-1, 1) 
  ) +
  scale_x_discrete(labels = ifelse(str_count(corr_labs) > 10, 
                            str_remove_all(corr_labs, "[aeiou]"), 
                            as.character(corr_labs))) +
  labs(x = NULL, y = NULL, fill = expression(rho), 
       title = "Matriz de correlación") +
  coord_fixed() +
  theme(panel.border = element_rect(color = NA, fill = NA),
        axis.text.y = element_text(margin = margin(0, 0, 0, 0)),
        axis.text.x = element_text(angle = 90),
        legend.background = element_rect(fill = "transparent"),
        legend.title = element_text(hjust = .1),
        legend.text.align = 1,
        legend.position = c(.75, .75),
        axis.ticks = element_blank())
```

Se observa correlación moderada-alta entre la antigüedad de la startup en su primer y último financiamiento. Esta correlación indica que el tiempo que transcurre entre ambos eventos cambia varía en forma lineal de empresa en empresa. A su vez, las variables mencionadas se correlacionan moderadamente con la antigüedad de la empresa en su primer/último hito.

Se estima que no hay correlaciones suficientemente altas entre los predictores, por ende, no se elimina ninguno del dataset. A continuación, se imputan los valores de latitud y longitud de las empresas ubicadas en el Mar Arábigo, con la media de sus vecinos más cercanos, utilizando las columnas `state_code`, `city` y `category_code`.


```{r}
outliers <- startup %>% 
  slice_max(latitude, n = 4) %>% 
  pull(name)

startup_to_impute <- startup %>% 
  mutate(latitude = if_else(name %in% outliers, NA_real_, latitude),
         longitude = if_else(name %in% outliers, NA_real_, longitude))


impute_recipe <- recipe(~ ., data = startup_to_impute) %>% 
  update_role(name, new_role = "id") %>% 
  step_other(state_code, threshold = 10) %>% 
  step_other(city, threshold = 10) %>% 
  step_other(category_code, threshold = 10, other = "Other") %>% 
  step_impute_knn(longitude, impute_with = c("state_code", "city", "category_code")) %>% 
  step_impute_knn(latitude, impute_with = c("state_code", "city", "category_code"))

imputed_values <- impute_recipe %>% 
  prep() %>% 
  bake(new_data = NULL) %>% 
  filter(name %in% outliers) %>% 
  select(lat = latitude, long = longitude, name)

startup_imputed <- startup_to_impute %>% 
  left_join(imputed_values, by = "name") %>% 
  mutate(latitude = if_else(is.na(latitude), lat, latitude),
         longitude = if_else(is.na(longitude), long, longitude)) %>% 
  select(-c(lat, long)) %>% 
  mutate(status = factor(status),
         id = row_number())
```


```{r}
startup_imputed %>% 
  select(where(anyNA)) %>% 
  pivot_longer(cols = everything()) %>% 
  ggplot(aes(value)) +
  geom_histogram(bins = 15) +
  facet_wrap(~name)
```


Finalmente, se particionan los datos en conjuntos de entrenamiento y prueba. A partir del conjunto de entrenamiento, se generan 25 conjuntos de validación utilizando* bootstrapping* estratificado.


```{r}
set.seed(123)
startup_split <- initial_split(startup_imputed, strata = status)
startup_train <- training(startup_split)
startup_test <- testing(startup_split)

set.seed(123)
startup_boost <- bootstraps(startup_train, times = 25, strata = status)
```


## Preprocesamiento de datos

Previo al entrenamiento de modelos con bootstrapping, se procede a realizar varias transformaciones sobre los datos:

- Se declara que el rol de las variables `name` y `id` es meramente identificador, es decir, no serán usadas para ajustar los modelos.
- Se agrupan las categorías con menos de 10 observaciones, de las variables `state_code`, `city` y `category_code`.
- Se crean variables dummy a partir de las categorías.
- Se extrae el año de las fechas.
- se realiza una transformación logarítmica sobre las variables `funding_total_usd` y `avg_participants`, porque sus distribuciones son de gran varianza y sesgo.
- Se normalizan ($\mu=0$ y $\sigma=1$) los predictores numéricos.
- Se muestrea con reemplazo el nivel minoritario (closed) de la variable respuesta, hasta alcanzar un ratio de 1 entre las categorías.


```{r message=FALSE, warning=FALSE}
library(themis)

preprocessing <- recipe(status ~ ., data = startup_train) %>% 
  update_role(name, id, new_role = "id") %>% 
  step_other(state_code, threshold = 10) %>% 
  step_other(city, threshold = 10) %>% 
  step_other(category_code, threshold = 10, other = "Other") %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_date(founded_at, first_funding_at, last_funding_at,
            features = "year", keep_original_cols = FALSE) %>% 
  step_log(funding_total_usd, avg_participants) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_upsample(status)
```


## Entrenamiento de red neuronal 1

Lo primero es crear una especificación de modelo de red neuronal, en este caso, de una sola capa. El hiperparámetro a optimizar es la cantidad de perceptrones en la capa oculta, denotado por el argumento `hidden_units = tune()`. Esta configuración, por defecto, especifica que se entrenará la red con una grilla de 10 valores, entre 1 y 10, para la cantidad de unidades ocultas.


```{r}
neural_net_1 <- mlp(hidden_units = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("keras")
```



















