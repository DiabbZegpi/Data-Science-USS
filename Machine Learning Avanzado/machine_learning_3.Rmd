---
title: "Taller 3 de Machine Learning Avanzado"
author: 
  - Araneda F., Marcela
  - Reyes G., Álvaro
  - Sepúlveda M., Danilo
  - Zegpi D., Diabb
output: 
  html_document:
    theme: united
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
ragg_png = function(..., res = 500) {
  ragg::agg_png(..., res = res, units = "in")
}

knitr::opts_chunk$set(
  echo = TRUE, 
  class.output = "purple-output",
  dev = "ragg_png", 
  fig.align = "center"
)
```

<style>
  body {
    font-size: 16px;
    background-color: #fff9fa;
  }
  
  pre {
    border: 0px;
  }

  .sourceCode, code {
    font-family: 'Fira Mono';
  }
  
  code {
    background-color: #e5eeeb;
    color: #111;
  }
  
  pre.sourceCode {
    color: #111;
    font-weight: 500;
    background-color: #e5eeeb;
  }
  
  code span.fu {
    color: #0e4747;
    font-weight: 600;
  }
  
  code span.sc {
    color: #ae4d00;
    font-weight: 600;
  }
  
  code span.st {
    color: #ae4d00;
  }
  
  .purple-output{
    background-color: #012626;
    color: #eee;
  }
</style>


```{r warning=FALSE, message=FALSE}
# Dependencias 
# install.packages(c("tidyverse", "tidymodels","here", "janitor", reticulate", "keras"))

library(tidyverse)
library(tidymodels)
library(here)
startup_raw <- read_csv(file = here("Machine Learning Avanzado", "startup data.csv")) %>% 
  janitor::clean_names()
```


```{r echo=FALSE}
library(ggtext)
theme_set(theme_light(base_family = "Segoe UI", base_size = 16))
theme_update(
  plot.background = element_rect(fill = "#fff9fa", color = "transparent"),
  panel.background = element_rect(fill = "#eeeeee"),
  text = element_text(color = "#111111"),
  plot.title = element_markdown(hjust = .5),
  plot.subtitle = element_markdown(hjust = .5),
  strip.background = element_rect(fill = "#fff9fa"),
  strip.text = element_text(color = "#111111", face = "italic", size = "16")
)
```


El dataset `startup` registra información de empresas emergentes (startups) en Estados Unidos. En total, contiene 923 filas y 49 columnas. Cada fila representa a una startup y cada columna a una característica de ésta. Inicialmente, hay muchas columnas que pueden ser construidos a partir de éstas, causando así duplicidad de datos. Por tanto, el primer análisis consistirá en determinar cuáles columnas pueden ser excluidas del dataset sin perder información relevante.

Las variables dummy a descartar serán reconstruidas en el proceso de modelamiento, pero, por el momento, serán excluidas.


```{r}
startup <- startup_raw %>% 
  select(-c(unnamed_0, zip_code, id, unnamed_6, labels, closed_at, state_code_1, object_id),
         -starts_with("is_")) 

colnames(startup)
```


El dataset resultante tiene `ncol(startup)` columnas, `select(startup, where(is.character)) %>% ncol()` de las cuales son categóricas y las demás son numéricas. De las columnas categóricas, 3 corresponden a fechas, por lo que se procede a adaptarlas.


```{r}
startup <- startup %>% 
  mutate(across(
    matches("fo?und") & where(is.character),
    function(x) as.Date(x, format = "%m/%d/%Y")            
  )) 
```


A continuación, se exploran descriptivamente todas las variables, de acuerdo con us tipo de dato.

### Variables categóricas
- No hay *missing data* en las columnas categóricas. 
- Las empresas provienen de 35 estados; el 52,9% es de California (CA).
- En total son 221 ciudades. San Francisco tiene la primera mayoría (13,9%).
- Las startups se dedican a 35 rubros. Las dos grandes mayorías son software (16,6%) y web (15,6%).
- Existe desequilibrio entre las dos clases de la variable objetivo `status`: acquired (64,7%) y closed (35,3%).
- Las columnas `has_` *vc*, *angel*, *round_{a, b, c, d}* son variables dummy no mutuamente excluyentes.


### Variables fecha
- Las empresas fueron fundadas entre el 1 de enero de 1984 y el 16 de abirl de 2013.
- Todas las empresas obtuvieron su primer financiamiento entre enero del 2000 y noviembre del 2013.
- Todas las empresas obtuvieron su último financiamiento entre enero del 2001 y noviembre del 2013.


## Variables numéricas
- La antigüedad de la empresa hasta su primer y último


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(maps)
main_states <- map_data("state")
ggplot() +
  geom_polygon(data = main_states, aes(long, lat, group = group),
               fill = "#012626", color = "white", size = .1) +
  geom_point(data = startup, aes(longitude, latitude),
             inherit.aes = FALSE, fill = "gold3", size = 5, 
             alpha = .4, shape = 21, color = "gray30", stroke = 1) +
  coord_cartesian(xlim = c(-125, -69), ylim = c(25, 50)) +
  theme_void()
```


El mapa superior muestra las empresas registradas en USA. Solamente hay 4 empresas fuera de USA: Xelerated en el Mar Arábigo (Sureste de Omán), Moli, DiJiPOP y Tracelytics, las tres en el Océano Índico, al Este de Somalia. Por supuesto, las cuatro empresas se encuentran adscritas a ciudades estadounidenses, por lo que sus coordenadas son susceptibles a imputación. Las demás variables numéricas se describen a continuación:

- Los rangos de las variables de antigüedad de las empresas hasta su primer o último financiamiento e hito incluyen números negativos. Esto se interpreta como factible.
- La antigüedad de las empresas hasta su primer y último hito tiene missing data. Se detecta dependencia entre estas variables y el *status* de las empresas.
- Las correlaciones entre las variables numéricas se muestran en la matriz de correlación.


```{r echo=FALSE, warning=FALSE, message=FALSE}
corm <-
  startup %>%
  select(where(is.numeric), -starts_with("has_"), -milestones) %>%
  corrr::correlate(diagonal = 1) %>%
  corrr::shave(upper = FALSE)

corm <- corm %>%
  pivot_longer(
    cols = -term,
    names_to = "colname",
    values_to = "corr"
  ) %>%
  mutate(rowname = fct_inorder(term),
         colname = fct_inorder(colname))

corr_labs <- unique(corm$rowname)

ggplot(corm, aes(rowname, fct_rev(colname), fill = corr)) +
  geom_tile(size = 2) +
  geom_text(aes(
    label = format(round(corr, 2), nsmall = 2),
    color = abs(corr) < .4
  )) +
  scale_color_manual(values = c("white", "black"), 
                     guide = "none", na.value = "#fff9fa") +
  scale_fill_gradient2(
    low = "#e5eeeb", mid = "#e5eeeb", high = "#012626", na.value = "#fff9fa",
    limits = c(-1, 1) 
  ) +
  scale_x_discrete(labels = ifelse(str_count(corr_labs) > 10, 
                            str_remove_all(corr_labs, "[aeiou]"), 
                            as.character(corr_labs))) +
  labs(x = NULL, y = NULL, fill = expression(rho), 
       title = "Matriz de correlación") +
  coord_fixed() +
  theme(panel.border = element_rect(color = NA, fill = NA),
        axis.text.y = element_text(margin = margin(0, 0, 0, 0)),
        axis.text.x = element_text(angle = 90),
        legend.background = element_rect(fill = "transparent"),
        legend.title = element_text(hjust = .1),
        legend.text.align = 1,
        legend.position = c(.75, .75),
        axis.ticks = element_blank(),
        plot.margin = unit(c(.5,3.3,.5,3.3), "cm"))
```

Se observa correlación moderada-alta entre la antigüedad de la startup en su primer y último financiamiento. Esta correlación indica que el tiempo que transcurre entre ambos eventos cambia varía en forma lineal de empresa en empresa. A su vez, las variables mencionadas se correlacionan moderadamente con la antigüedad de la empresa en su primer/último hito.

Se estima que no hay correlaciones suficientemente altas entre los predictores, por ende, no se elimina ninguno del dataset. A continuación, se imputan los valores de latitud y longitud de las empresas ubicadas en el Mar Arábigo, con la media de sus vecinos más cercanos, utilizando las columnas `state_code`, `city` y `category_code`.

Respecto a las columnas `age_first_milestone_year` y `age_last_milestone_year`, ambas tienen 152 valores faltantes, en los mismos registros. Además, esto se condice con la columna `milestones`: la startup no registra milestones si y solo si adolesce de valores faltantes. Por simplicidad, las dos columnas `age_` serán excluidas del dataset.


```{r}
outliers <- startup %>% 
  slice_max(latitude, n = 4) %>% 
  pull(name)

startup_to_impute <- startup %>% 
  mutate(latitude = if_else(name %in% outliers, NA_real_, latitude),
         longitude = if_else(name %in% outliers, NA_real_, longitude))


impute_recipe <- recipe(~ ., data = startup_to_impute) %>% 
  update_role(name, new_role = "id") %>% 
  step_other(state_code, threshold = 10) %>% 
  step_other(city, threshold = 10) %>% 
  step_other(category_code, threshold = 10, other = "Other") %>% 
  step_impute_knn(longitude, impute_with = c("state_code", "city", "category_code")) %>% 
  step_impute_knn(latitude, impute_with = c("state_code", "city", "category_code"))

imputed_values <- impute_recipe %>% 
  prep() %>% 
  bake(new_data = NULL) %>% 
  filter(name %in% outliers) %>% 
  select(lat = latitude, long = longitude, name)

startup_imputed <- startup_to_impute %>% 
  left_join(imputed_values, by = "name") %>% 
  mutate(latitude = if_else(is.na(latitude), lat, latitude),
         longitude = if_else(is.na(longitude), long, longitude)) %>% 
  select(-c(lat, long, age_first_milestone_year, age_last_milestone_year)) %>% 
  mutate(status = factor(status),
         id = row_number())
```


Finalmente, se particionan los datos en conjuntos de entrenamiento y prueba. A partir del conjunto de entrenamiento, se generan 10 conjuntos de validación utilizando* bootstrapping* estratificado.


```{r}
set.seed(123)
startup_split <- initial_split(startup_imputed, strata = status)
startup_train <- training(startup_split)
startup_test <- testing(startup_split)

set.seed(123)
startup_boots <- bootstraps(startup_train, times = 10, strata = status)
```


## Preprocesamiento de datos

Previo al entrenamiento de modelos con bootstrapping, se procede a realizar varias transformaciones sobre los datos:

- Se declara que el rol de las variables `name` y `id` es meramente identificador, es decir, no serán usadas para ajustar los modelos.
- Se agrupan las categorías con menos de 10 observaciones, de las variables `state_code`, `city` y `category_code`.
- Se crean variables dummy a partir de las categorías.
- Se extrae el año de las fechas.
- se realiza una transformación logarítmica sobre las variables `funding_total_usd` y `avg_participants`, porque sus distribuciones son de gran varianza y sesgo.
- Se normalizan ($\mu=0$ y $\sigma=1$) los predictores numéricos.
- Se muestrea con reemplazo el nivel minoritario (closed) de la variable respuesta, hasta alcanzar un ratio de 1 entre las categorías.


```{r message=FALSE, warning=FALSE}
library(themis)

preprocessing <- recipe(status ~ ., data = startup_train) %>% 
  update_role(name, id, new_role = "id") %>% 
  step_other(state_code, threshold = 10) %>% 
  step_other(city, threshold = 10) %>% 
  step_other(category_code, threshold = 10, other = "Other") %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_date(founded_at, first_funding_at, last_funding_at,
            features = "year", keep_original_cols = FALSE) %>% 
  step_log(funding_total_usd, avg_participants) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_upsample(status)
```


## Entrenamiento de red neuronal 1

Lo primero es crear una especificación de modelo de red neuronal, en este caso, de una sola capa. El hiperparámetro a optimizar es la cantidad de perceptrones en la capa oculta, denotado por el argumento `hidden_units = tune()`. Esta configuración, por defecto, especifica que se entrenará la red con una grilla de 10 valores, entre 1 y 10, para la cantidad de unidades ocultas. La función de activación por defecto para problemas de clasificación es *softmax*.


```{r}
neural_net_1 <- mlp(hidden_units = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("nnet")
neural_net_1
```


Luego, se incorporan tanto la especificación del modelo como las instrucciones de preprocesamiento en un objeto *workflow*.

```{r}
nnet_wf <- workflow() %>% 
  add_recipe(preprocessing) %>% 
  add_model(neural_net_1)
nnet_wf
```


```{r eval=FALSE}
library(doParallel)
ncores <- detectCores() - 1
cl <- makePSOCKcluster(ncores)
registerDoParallel(cl)

nnet_grid_1 <- grid_regular(hidden_units(), levels = 10)

set.seed(123)
nnet_results_1 <- tune_grid(
  nnet_wf,
  resamples = startup_boots,
  grid = nnet_grid_1,
  control = control_grid(save_pred = TRUE, allow_par = TRUE)
)

stopImplicitCluster()
```


```{r echo=FALSE, eval=FALSE}
saveRDS(nnet_results_1, file = here("Machine Learning Avanzado", "nnet_results_1.rds"))
```


```{r echo=FALSE}
nnet_results_1 <- readRDS(file = here("Machine Learning Avanzado", "nnet_results_1.rds"))
```


## Entrenamiento de SVM

Para el modelo de SVM se utilizar el mismo preprocesador que para la red neuronal.


```{r}
svm_spec <- svm_rbf() %>% 
  set_mode("classification") %>% 
  set_engine("kernlab")


svm_wf <- workflow() %>% 
  add_recipe(preprocessing) %>% 
  add_model(svm_spec)
svm_wf
```


```{r eval=FALSE}
registerDoParallel(cl)

svm_results <- fit_resamples(
  svm_wf, 
  resamples = startup_boots,
  control = control_resamples(save_pred = TRUE, allow_par = TRUE)
)

stopImplicitCluster()
```


```{r echo=FALSE, eval=FALSE}
saveRDS(svm_results, file = here("Machine Learning Avanzado", "svm_results.rds"))
```


```{r echo=FALSE}
svm_results <- readRDS(file = here("Machine Learning Avanzado", "svm_results.rds"))
```


```{r echo=FALSE}
svm_accuracy <- svm_results %>% 
  collect_metrics() %>% 
  filter(.metric == "accuracy")

svm_accuracy <- map_dfr(-1:11, function(x) svm_accuracy) %>% 
  mutate(hidden_units = -1:11)

nnet_results_1 %>% 
  collect_metrics() %>% 
  filter(.metric == "accuracy") %>% 
  ggplot(aes(hidden_units, mean)) +
  geom_errorbar(aes(ymax = mean + std_err, ymin = mean - std_err), width = .3) +
  geom_point(size = 4, shape = 21, fill = "white", color = "#111111", stroke = 2) +
  geom_ribbon(data = svm_accuracy, 
              aes(ymax = mean + std_err, ymin = mean - std_err),
              alpha = .2) +
  geom_hline(data = svm_accuracy, aes(yintercept = mean), linetype = 2) +
  geom_curve(aes(x = 2, xend = 2.2, y = .6615, yend = .65), curvature = .2, size = .2) +
  geom_curve(aes(x = 2, xend = 2.8, y = .6865, yend = .65), curvature = -.3, size = .2) +
  annotate("text", x = 2.6, y = .642, size = 5,
           label= "Red Neuronal\nAccuracy estimado ± error estandar") +
  annotate("text", x = 5.5, y = .702, size = 5,
           label= "Support Vector Machine\nAccuracy estimado ± error estandar") +
  scale_y_continuous(labels = percent_format(), limits = c(.62, .72), expand = c(.01, .01)) + 
  scale_x_continuous(expand = c(0, 0), limits = c(0, 11), 
                     labels = c(0, 2, 4, 6, 8, 10), breaks = c(0, 2, 4, 6, 8, 10)) + 
  labs(title = "Red neuronal vs SVM", y = "Accuracy", x = "# hidden units")
```


Evidentemente, la red neuronal no alcanza el accuracy del modelo SVM, de aproximadamente 70% de las clasificaciones correctas. Aun asi, los resultados obtenidos por SVM no son alentadores. La matriz de confusion de SVM para todos los conjuntos de bootstrap expone que ambas clases son equitativamente dificiles para el modelo. Por otra parte, tras analizar la proporcion de cada clase, es evidente que la tasa de `closed` verdaderos es menor que la de `acquired`. Por lo tanto, al modelo SVM predice con menor precision que una startup haya cerrado.


```{r}
svm_results %>% 
  collect_predictions() %>% 
  conf_mat(truth = status, .pred_class) 
```







