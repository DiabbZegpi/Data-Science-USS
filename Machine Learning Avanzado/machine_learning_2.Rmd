---
title: "Taller 2 de Machine Learning Avanzado"
author: "Zegpi D., Diabb"
output: 
  html_document:
    theme: united
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
ragg_png = function(..., res = 500) {
  ragg::agg_png(..., res = res, units = "in")
}

knitr::opts_chunk$set(
  echo = TRUE, 
  class.output = "purple-output",
  dev = "ragg_png", 
  fig.align = "center"
)
```

<style>
  body {
    font-size: 16px;
    background-color: #fff9fa;
  }
  
  pre {
    border: 0px;
  }

  .sourceCode, code {
    font-family: 'Fira Mono';
  }
  
  code {
    background-color: #e5eeeb;
    color: #111;
  }
  
  pre.sourceCode {
    color: #111;
    font-weight: 500;
    background-color: #e5eeeb;
  }
  
  code span.fu {
    color: #0e4747;
    font-weight: 600;
  }
  
  code span.sc {
    color: #ae4d00;
    font-weight: 600;
  }
  
  code span.st {
    color: #ae4d00;
  }
  
  .purple-output{
    background-color: #012626;
    color: #eee;
  }
</style>


```{r warning=FALSE, message=FALSE}
# Dependencias 
# install.packages(c("tidyverse", "tidymodels", "ranger", "here", "vip"))

library(tidyverse)
library(tidymodels)
library(here)
titanic_train <- read_csv(here("Machine Learning Avanzado", "train.csv"))
titanic_test <- read_csv(here("Machine Learning Avanzado", "test.csv"))
titanic_train$Survived <- factor(titanic_train$Survived)
```

```{r echo=FALSE}
library(ggtext)
theme_set(theme_light(base_family = "Segoe UI", base_size = 16))
theme_update(
  plot.background = element_rect(fill = "#fff9fa", color = "transparent"),
  panel.background = element_rect(fill = "#eeeeee"),
  text = element_text(color = "#111111"),
  plot.title = element_text(hjust = .5),
  plot.subtitle = element_markdown(hjust = .5),
  strip.background = element_rect(fill = "#fff9fa"),
  strip.text = element_text(color = "#111111", face = "italic", size = "16")
)
```

Primero que todo, se necesita saber cuáles campos tiene `titanic_train` que `titanic_test` no contenga, con el objetivo de evitar *data leakage*.

```{r}
colnames(titanic_train[!colnames(titanic_train) %in% colnames(titanic_test)])
```

La única columna que no se encuentra en el conjunto de prueba es `Survived`. Posteriormente, se examina el dataset de entrenamiento en búsqueda de valores faltantes.

```{r}
titanic_train %>% 
  summarise(across(everything(), ~sum(is.na(.)))) %>% 
  pivot_longer(cols = everything(), names_to = "Campo", values_to = "NAs") %>% 
  mutate("% de NAs" = round(100 * NAs / nrow(titanic_train), 2)) %>% 
  print(n = Inf)
```

De acuerdo al resultado anterior, es necesario tratar con las columnas `Age`, `Cabin` y `Embarked`.

### Tratamiento de valores faltantes

Para el caso de la variable `Embarked` se imputará por la moda, debido a que el 72% de los pasajeros abordaron en Southampton.

El gran porcentaje de valores faltantes de la columna `Cabin` (77%) le convierte en un candidato a eliminar del dataset. Sin embargo, ha de investigarse si estos valores faltantes se condicen con algún patrón relacionado con la variable dependiente `Survived` u otras variables. En otras palabras, ha de investigarse si los registros en cuestión pertenecen a la categoría MAR, MNAR o MCAR.  

```{r}
cabin_data <- 
  titanic_train %>% 
  mutate(Cabin = ifelse(is.na(Cabin), "no", "yes")) %>% 
  select(Survived, Cabin)

table(cabin_data)
```

Aparentemente, existe una relación entre la variable objetivo y si el pasajero/a registra o no el número de cabina. Para contrastar si esta relación existe y en caso que existiere, medir su fuerza relativa, se conduce una prueba de *chi cuadrado* y se calcula el *coeficiente de phi*, respectivamente. La hipótesis nula $H_0$ propone que ambas variables, `Survived` y `Cabin` son independientes; la hipótesis alternativa $H_A$ propone que existe dependencia entre ambas variables.

```{r}
cabin_data %>% {chisq.test(.$Survived, .$Cabin)}
```

Con un nivel de significancia del 5% se rechaza la hipótesis nula, concluyendo que se observa evidencia suficiente de dependencia entre las variables contrastadas. A continuación, se calcula el coeficiente de phi de la forma

$$\phi = \sqrt{\frac{\chi^2}{n}} \hspace{1cm} 0 \leq \phi \leq 1,$$

donde $\chi^2$ es el estadístico de la prueba chi cuadrado y $n$ es la cantidad de observaciones (pasajeros). El coeficiente estimado es de `r cabin_data %>% {chisq.test(.$Survived, .$"Cabin")} %>% {.$statistic / nrow(cabin_data)} %>% sqrt() %>% round(2)`, lo que indica una relación entre débil y moderada, sugiriendo que existe poder predictivo en la variable `Cabin` para predecir si un pasajero sobrevivió a la tragedia. En otras palabras, los datos faltantes corresponden a la categoría de MAR (*Missing At Random*) y es conveniente conservarlos en el dataset.

Antes de decidir un método para la imputación de la columna `Age`, es adecuado observar la distribución de las edades de los pasajeros.

```{r echo=FALSE}
titanic_train %>% 
  ggplot(aes(Age)) +
  geom_histogram(na.rm = TRUE, bins = 25, alpha = .8, fill = "#012626") +
  labs(x = "Age", y = "Frecuencia absoluta", 
       title = "Histograma de Age") +
  stat_bin(geom = "text", aes(label = ..count.., y = ..count.. + 3), bins = 25, na.rm = T)
```

En apariencia, la distribución de edad de los pasajeros es bimodal, con grupos bien definidos de población de menores y de adultos. El primer grupo etáreo alcanzaría el 19% de los pasajeros. Por supuesto, esto correlaciona con la distribución de títulos de los pasajeros: 

```{r}
extract_title <- function(x) {
  x %>% 
    stringr::str_extract("Mr\\.? |Mrs\\.?|Miss\\.?|Master\\.?") %>% 
    stringr::str_remove("\\.") %>% 
    if_else(is.na(.), "Other", .)
}

titanic_train %>% 
  mutate(Title = if_else(is.na(extract_title(Name)), "Other", extract_title(Name))) %>% 
  group_by(Title) %>% 
  summarize(across(Age, list("Min Age" = min, "Max Age" = max), na.rm = TRUE, .names = "{.fn}"))
```

Los grupos con títulos masculinos están bien caracterizados, y una estimación de la edad por la media del grupo sería más adecuada que estimar por la media de la muestra completa. Sin embargo, los títulos femeninos presentan solapamiento.

```{r echo=FALSE}
miss_mrs <- tibble(label = "La distribución de la edad de las pasajeras<br>del Titanic es mixta y se compone de los<br>subgrupos <b style='color:#592759;'>Miss.</b> y <b style='color:#354f79;'>Mrs.</b>",
                   x = 47, y = 22)

titanic_train %>% 
  mutate(Title = extract_title(Name)) %>% 
  filter(Sex == "female" & Title != "Other") %>% 
  ggplot(aes(Age, fill = Title)) +
  geom_histogram(bins = 15, position = "identity", na.rm = TRUE, alpha = .8, show.legend = FALSE) +
  geom_richtext(data = miss_mrs, inherit.aes = FALSE, 
                fill = NA, label.color = NA, size = 4.5, family = "Noto Sans", fontface = "italic",
                aes(x = x, y = y, label = label)) +
  scale_fill_manual(values = c("#592759", "#354f79")) +
  labs(title = "Distribución de la edad de las pasajeras por título",
       x = "Age", y = "Frecuencia absoluta")
```

Se observa que pese al traslape de las distribuciones, la edad sí puede ser caracterizada por el título de la pasajera. Finalmente, los valores faltantes de edad serán imputados con el algoritmo *KNN* y utilizando la *distancia de Gower*, cuyos predictores serán las variables `Title`, `Sex`, `SibSp` y `Parch`.

Finalmente, el conjunto de prueba presenta un valor faltante en la columna `Fare`. Este será imputado con los vecinos más cercanos utilizando `Age`, `Sex`, `Embarked` y `Pclass`.

### Imputación de los valores faltantes

Para culminar el tratamiento de los datos faltantes, las transformaciones e imputaciones se llevarán a cabo utilizando el framework de machine learning `tidymodels`, porque facilita la incorporación de las etapas de procesamiento de datos en el flujo de trabajo de data science. 

El primer paso es separar los datos de entrenamiento en entrenamiento y validación, con 3/4 de los datos en el conjunto de entrenamiento. Luego, se crea un objeto de *receta* que contendrá todas las etapas del procesamiento deseadas. Esta receta se usará posteriormente para crear el dataset al que se ajustará un modelo de *random forests*, por ésto el nombre de `rf_recipe`. Después, se incorporan la imputación por la moda de `Embarked`, la transformación de la columna `Cabin`, la creación de la columna `Title` y la imputación con KNN de la columna `Age`. 

Random forest no requiere preprocesamiento exhaustivo sobre los datos de entrenamiento, tales como transformaciones matemáticas (logaritmo de `Fare` o z-score de `Age`) y creación de variables dummy. Además, cabe destacar que `bake()` aplica las transformaciones de la receta a nuevos conjuntos de datos; si `new_data = NULL` entonces retorna los datos de entrenamientos transformados; si `new_data = titanic_test`, se aplican las transformaciones **calculadas sobre el conjunto de entrenamiento** para retornar el conjunto de prueba transformado, evitando así data leakage. 

```{r}
set.seed(123)
titanic_split <- initial_split(titanic_train, strata = Survived)
titanic_train <- training(titanic_split)
titanic_val <- testing(titanic_split)

rf_recipe <- 
  recipe(~ ., data = titanic_train) %>% 
  step_impute_mode(Embarked) %>% 
  step_mutate(Cabin = if_else(is.na(Cabin), "Yes", "No"),
              Title = extract_title(Name)) %>% 
  step_impute_knn(Age, impute_with = c("Title", "Sex", "SibSp", "Parch")) %>% 
  step_impute_knn(Fare, impute_with = c("Age", "Sex", "Embarked", "Pclass"))

prep_recipe <- prep(rf_recipe)  
train_processed <- bake(prep_recipe, new_data = NULL)
val_processed <- bake(prep_recipe, new_data = titanic_val %>%
                         mutate(across(where(is.character), as.factor)))
test_processed <- bake(prep_recipe, new_data = titanic_test %>%
                         mutate(across(where(is.character), as.factor)))
```

### Resampling y afinación de hiperparámetros

Debido a que el dataset es pequeño como para crear un conjunto de validación que sirva para la estimación del desempeño del modelo, se utilizará el método de *10-fold cross validation*.

```{r}
set.seed(123)
titanic_folds <- vfold_cv(train_processed, v = 10)
```

Los errores de entrenamiento y validación serán calculados para cada uno de los subconjuntos en `titanic_folds`, estimando el error de validación como la media de los 10 errores de validación parciales.

Paralelamente, se declara la especificación del modelo de ranfom forests utilizando engine del paquete `ranger`, en *modo clasificación*. Los hiperparámetros a afinar se definen a continuación:

- **mtry**: un entero para el número de predictores que son muestreados aleatoriamente en cada separación al crear los modelos de árbol.

- **min_n**: un entero para el número mínimo de puntos necesarios en un nodo para que pueda seguir dividiéndose.

- **trees**: un entero para el número de árboles contenidos en el ensamblaje.

```{r}
rf_spec <- 
  rand_forest(
    mtry = tune(),
    min_n = tune(),
    trees = tune()
  ) %>% 
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")
```

Se elige usar un método de búsqueda en grilla para optimizar la combinación de hiperparámetros. El diseño de grilla escogido es de hipercubo. Debido a que el hiperparámetro mtry depende de las dimensiones del dataset, el framework de tidymodels requiere que se finalice el parámetro con el rango de dimensiones correctas (entre 1 y 10 porque hay 10 variables: 1 objetivo y 9 predictoras).

```{r}
set.seed(123)
rf_grid <- 
  grid_latin_hypercube(
    rf_spec %>% 
      parameters() %>% 
      update(mtry = range_set(mtry(), c(1, 9)),
             trees = range_set(trees(), c(200, 2000))),
    size = 200
  )
```

Una vez se tienen los componentes más importantes del framework de tidymodels (preprocesamiento, especificación de modelo, resampling y mecanismo de afinación de hiperparámetros), se procede a crear un workflow que los haga interactuar.

```{r}
rf_formula <- formula(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Cabin + Embarked + Title)
rf_wf <- 
  workflow() %>% 
  add_model(rf_spec) %>% 
  add_formula(rf_formula)
```

Afinar 200 combinaciones de hiperparámetros en 10 subconjuntos de datos implica ajustar 2000 veces el modelo de random forest, con una cantidad de árboles que varía entre 200 y 2000. Para acelerar los cálculos, se permite que tidymodels acceda a los múltiples cores que tiene el computador mediante computación paralela, con `doParallel`.

```{r eval=FALSE}
doParallel::registerDoParallel()
set.seed(123)
rf_res <- tune_grid(
  rf_wf,
  resamples = titanic_folds,
  grid = rf_grid,
  control = control_resamples(save_pred = TRUE)
)
```

```{r echo=FALSE, eval=FALSE}
write_rds(rf_res, file = here("Machine Learning Avanzado", "rf_res_titanic.rds"))
```

```{r echo=FALSE}
rf_res <- read_rds(file = here("Machine Learning Avanzado", "rf_res_titanic.rds"))
```

La combinación de hiperparámetros que optimiza accuracy resultó ser trees: 799, mtry: 4 y min_n: 22. Esta combinación alcanzó un accuracy estimado de 0.846, con un error estándar estimado de 0.0169. Paralelamente, el área media bajo la curva ROC estimada es 0.889, con error estándar de 0.0156.

```{r echo=FALSE, fig.width=11}
collect_metrics(rf_res) %>% 
  filter(.metric == "accuracy") %>% 
  pivot_longer(mtry:min_n) %>% 
  group_by(name) %>% 
  mutate(best = ifelse(mean == max(mean), "best", "not best")) %>% 
  ungroup() %>% 
  ggplot(aes(value, mean, color = name, size = mean)) +
  geom_point(show.legend = FALSE, alpha = .5) +
  geom_smooth(show.legend = FALSE, method = "loess", formula = y ~ x) +
  scale_color_manual(values = c("#a92759", "#354fa9", "#018666")) +
  facet_wrap(~name, scales = "free_x") +
  labs(title = "Ajuste de hiperparámetros con validación cruzada",
       x = "Valor del hiperparámetro", y = "Exactitud media de clasificación") 
```

```{r echo=FALSE}
collect_predictions(rf_res) %>% 
  group_by(.config) %>%  
  roc_curve(Survived, .pred_0) %>% 
  ggplot(aes(1 - specificity, sensitivity)) +
  geom_line(show.legend = FALSE, alpha = .7, size = .4, aes(group = .config), color = "gray50") +
  stat_summary(geom = "line", fun = mean, color = "#a92759", size = 1) +
  geom_abline(linetype = 2) +
  annotate(geom = "text", x = .45, y = .35, size = 4.5, family = "Noto Sans", fontface = "italic",
           label = "ROC AUC media = 0.889\nStd. Error = 0.0156", hjust = 0) +
  coord_fixed() +
  labs(title = "Curva ROC del ajuste de hiperparámetros") +
  theme(plot.margin = unit(c(.5,3.3,.5,3.3), "cm"))
```

Sin embargo, prevalece la pregunta: para obtener el mejor conjunto de hiperparámetros ¿conviene optimizar accuracy o el área bajo la curva ROC? Para descubrir qué métrica conviene utilizar, se ajustan dos modelos de random forest, con las configuraciones óptimas de hiperparámetros para accuracy y área bajo la curva ROC, respectivamente.

```{r}
best_accuracy <- select_best(rf_res, metric = "accuracy")
best_roc <- select_best(rf_res, metric = "roc_auc")
final_wf_accuracy <- rf_wf %>% update_model(finalize_model(rf_spec, best_accuracy))
final_wf_roc <- rf_wf %>% update_model(finalize_model(rf_spec, best_roc))
set.seed(123)
rf_fit_accuracy <- fit(final_wf_accuracy, data = train_processed)
set.seed(123)
rf_fit_roc <- fit(final_wf_roc, data = train_processed)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=9, fig.height=6}
bind_rows(train = train_processed, validation = val_processed, .id = "set") %>% 
  nest(data = all_of(2:ncol(.))) %>% 
  mutate(pred_accuracy = map(data, ~predict(rf_fit_accuracy, new_data = .x)),
         pred_roc = map(data, ~predict(rf_fit_roc, new_data = .x))) %>% 
  unnest(cols = c(data, pred_accuracy, pred_roc), names_repair = "universal") %>% 
  rename("Best Accuracy" = .pred_class...15, "Best ROC AUC" = .pred_class...16) %>%
  pivot_longer(cols = starts_with("Best"), names_to = "metric", values_to = ".pred_class") %>% 
  relocate(set, metric) %>% 
  nest(data = all_of(3:ncol(.))) %>% 
  mutate(accuracy = map(data, ~accuracy(.x, Survived, .pred_class)),
         accuracy = map_dbl(accuracy, ".estimate"),
         sensitivity = map(data, ~sensitivity(.x, Survived, .pred_class)),
         sensitivity = map_dbl(sensitivity, ".estimate"),
         specificity = map(data, ~specificity(.x, Survived, .pred_class)),
         specificity = map_dbl(specificity, ".estimate")) %>%  
  pivot_longer(cols = accuracy:specificity) %>% 
  ggplot(aes(set, value, color = name, group = name)) +
  geom_line(size = 1) +
  geom_label(aes(label = round(value, 3)), size = 5, fontface = "bold", label.size = 1) +
  scale_color_manual(values = c("#a92759", "#354fa9", "#018666")) +
  coord_cartesian(ylim = c(.7, 1)) +
  facet_wrap(~metric) +
  theme(legend.position = "none") +
  labs(x = "Set", y = "Valor de la métrica", 
       title = "¿Optimizar Accuracy o ROC AUC?",
       subtitle = "Comparación entre <b style='color:#354fa9;'>sensitivity</b>, <b style='color:#a92759;'>accuracy</b> y <b style='color:#018666;'>specificity</b>") 
```

Se observa que ambos modelos tienden a sobreajustarse. La configuración para el mejor accuracy sobreajusta menos que la configuración con mejor ROC AUC, porque la diferencia entre las métricas de desempeño calculadas en los conjuntos de entrenamiento y validación es menor. Por lo tanto, se escoge la configuración del mejor accuracy para realizar las predicciones sobre el conjunto de prueba.

```{r echo=FALSE, eval=FALSE}
vip::vip(rf_fit$fit$fit)
```






















