---
title: "Taller 2 de Machine Learning Avanzado"
author: "Zegpi D., Diabb"
output: 
  html_document:
    theme: united
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
ragg_png = function(..., res = 500) {
  ragg::agg_png(..., res = res, units = "in")
}

knitr::opts_chunk$set(
  echo = TRUE, 
  class.output = "purple-output",
  dev = "ragg_png", 
  fig.align = "center"
)
```

<style>
  body {
    font-size: 16px;
    background-color: #fff9fa;
  }
  
  pre {
    border: 0px;
  }

  .sourceCode, code {
    font-family: 'Fira Mono';
  }
  
  code {
    background-color: #e5eeeb;
    color: #111;
  }
  
  pre.sourceCode {
    color: #111;
    font-weight: 500;
    background-color: #e5eeeb;
  }
  
  code span.fu {
    color: #0e4747;
    font-weight: 600;
  }
  
  code span.sc {
    color: #ae4d00;
    font-weight: 600;
  }
  
  code span.st {
    color: #ae4d00;
  }
  
  .purple-output{
    background-color: #012626;
    color: #eee;
  }
</style>


```{r warning=FALSE, message=FALSE}
# Dependencias 
# install.packages(c("tidyverse", "tidymodels", "ranger", "here", "vip"))

library(tidyverse)
library(tidymodels)
library(here)
titanic_train <- read_csv(here("Machine Learning Avanzado", "train.csv"))
titanic_test <- read_csv(here("Machine Learning Avanzado", "test.csv"))
titanic_train$Survived <- factor(titanic_train$Survived)
```

```{r echo=FALSE}
library(ggtext)
theme_set(theme_light(base_family = "Segoe UI", base_size = 16))
theme_update(
  plot.background = element_rect(fill = "#fff9fa", color = "transparent"),
  panel.background = element_rect(fill = "#eeeeee"),
  text = element_text(color = "#111111"),
  plot.title = element_markdown(hjust = .5),
  plot.subtitle = element_markdown(hjust = .5),
  strip.background = element_rect(fill = "#fff9fa"),
  strip.text = element_text(color = "#111111", face = "italic", size = "16")
)
```

Primero que todo, se necesita saber cuáles campos tiene `titanic_train` que `titanic_test` no contenga, con el objetivo de evitar *data leakage*.

```{r}
colnames(titanic_train[!colnames(titanic_train) %in% colnames(titanic_test)])
```

La única columna que no se encuentra en el conjunto de prueba es `Survived`. Posteriormente, se examina el dataset de entrenamiento en búsqueda de valores faltantes.

```{r}
titanic_train %>% 
  summarise(across(everything(), ~sum(is.na(.)))) %>% 
  pivot_longer(cols = everything(), names_to = "Campo", values_to = "NAs") %>% 
  mutate("% de NAs" = round(100 * NAs / nrow(titanic_train), 2)) %>% 
  print(n = Inf)
```

De acuerdo al resultado anterior, es necesario tratar con las columnas `Age`, `Cabin` y `Embarked`.

### Tratamiento de valores faltantes

Para el caso de la variable `Embarked` se imputará por la moda, debido a que el 72% de los pasajeros abordaron en Southampton.

El gran porcentaje de valores faltantes de la columna `Cabin` (77%) le convierte en un candidato a eliminar del dataset. Sin embargo, ha de investigarse si estos valores faltantes se condicen con algún patrón relacionado con la variable dependiente `Survived` u otras variables. En otras palabras, ha de investigarse si los registros en cuestión pertenecen a la categoría MAR, MNAR o MCAR.  

```{r}
cabin_data <- 
  titanic_train %>% 
  mutate(Cabin = ifelse(is.na(Cabin), "no", "yes")) %>% 
  select(Survived, Cabin)

table(cabin_data)
```

Aparentemente, existe una relación entre la variable objetivo y si el pasajero/a registra o no el número de cabina. Para contrastar si esta relación existe y en caso que existiere, medir su fuerza relativa, se conduce una prueba de *chi cuadrado* y se calcula el *coeficiente de phi*, respectivamente. La hipótesis nula $H_0$ propone que ambas variables, `Survived` y `Cabin` son independientes; la hipótesis alternativa $H_A$ propone que existe dependencia entre ambas variables.

```{r}
cabin_data %>% {chisq.test(.$Survived, .$Cabin)}
```

Con un nivel de significancia del 5% se rechaza la hipótesis nula, concluyendo que se observa evidencia suficiente de dependencia entre las variables contrastadas. A continuación, se calcula el coeficiente de phi de la forma

$$\phi = \sqrt{\frac{\chi^2}{n}} \hspace{1cm} 0 \leq \phi \leq 1,$$

donde $\chi^2$ es el estadístico de la prueba chi cuadrado y $n$ es la cantidad de observaciones (pasajeros). El coeficiente estimado es de `r cabin_data %>% {chisq.test(.$Survived, .$"Cabin")} %>% {.$statistic / nrow(cabin_data)} %>% sqrt() %>% round(2)`, lo que indica una relación entre débil y moderada, sugiriendo que existe poder predictivo en la variable `Cabin` para predecir si un pasajero sobrevivió a la tragedia. En otras palabras, los datos faltantes corresponden a la categoría de MAR (*Missing At Random*) y es conveniente conservarlos en el dataset.

Antes de decidir un método para la imputación de la columna `Age`, es adecuado observar la distribución de las edades de los pasajeros.

```{r echo=FALSE}
titanic_train %>% 
  ggplot(aes(Age)) +
  geom_histogram(na.rm = TRUE, bins = 25, alpha = .8, fill = "#012626") +
  labs(x = "Age", y = "Frecuencia absoluta", 
       title = "Histograma de Age") +
  stat_bin(geom = "text", aes(label = ..count.., y = ..count.. + 3), bins = 25, na.rm = T)
```

En apariencia, la distribución de edad de los pasajeros es bimodal, con grupos bien definidos de población de menores y de adultos. El primer grupo etáreo alcanzaría el 19% de los pasajeros. Por supuesto, esto correlaciona con la distribución de títulos de los pasajeros: 

```{r}
extract_title <- function(x) {
  x %>% 
    stringr::str_extract("Mr\\.? |Mrs\\.?|Miss\\.?|Master\\.?") %>% 
    stringr::str_remove("\\.") %>% 
    if_else(is.na(.), "Other", .)
}

titanic_train %>% 
  mutate(Title = if_else(is.na(extract_title(Name)), "Other", extract_title(Name))) %>% 
  group_by(Title) %>% 
  summarize(across(Age, list("Min Age" = min, "Max Age" = max), na.rm = TRUE, .names = "{.fn}"))
```

Los grupos con títulos masculinos están bien caracterizados, y una estimación de la edad por la media del grupo sería más adecuada que estimar por la media de la muestra completa. Sin embargo, los títulos femeninos presentan solapamiento.

```{r echo=FALSE}
miss_mrs <- tibble(label = "La distribución de la edad de las pasajeras<br>del Titanic es mixta y se compone de los<br>subgrupos <b style='color:#592759;'>Miss.</b> y <b style='color:#354f79;'>Mrs.</b>",
                   x = 47, y = 22)

titanic_train %>% 
  mutate(Title = extract_title(Name)) %>% 
  filter(Sex == "female" & Title != "Other") %>% 
  ggplot(aes(Age, fill = Title)) +
  geom_histogram(bins = 15, position = "identity", na.rm = TRUE, alpha = .8, show.legend = FALSE) +
  geom_richtext(data = miss_mrs, inherit.aes = FALSE, 
                fill = NA, label.color = NA, size = 4.5, family = "Noto Sans", fontface = "italic",
                aes(x = x, y = y, label = label)) +
  scale_fill_manual(values = c("#592759", "#354f79")) +
  labs(title = "Distribución de la edad de las pasajeras por título",
       x = "Age", y = "Frecuencia absoluta")
```

Se observa que pese al traslape de las distribuciones, la edad sí puede ser caracterizada por el título de la pasajera. Finalmente, los valores faltantes de edad serán imputados con el algoritmo *KNN* y utilizando la *distancia de Gower*, cuyos predictores serán las variables `Title`, `Sex`, `SibSp` y `Parch`.

Finalmente, el conjunto de prueba presenta un valor faltante en la columna `Fare`. Este será imputado con los vecinos más cercanos utilizando `Age`, `Sex`, `Embarked` y `Pclass`.

### Imputación de los valores faltantes

Para culminar el tratamiento de los datos faltantes, las transformaciones e imputaciones se llevarán a cabo utilizando el framework de machine learning `tidymodels`, porque facilita la incorporación de las etapas de procesamiento de datos en el flujo de trabajo de data science. 

El primer paso es separar los datos de entrenamiento en entrenamiento y validación, con 3/4 de los datos en el conjunto de entrenamiento. Luego, se crea un objeto de *receta* que contendrá todas las etapas del procesamiento deseadas. Esta receta se usará posteriormente para crear el dataset al que se ajustará un modelo de *random forests*, por ésto el nombre de `rf_recipe`. Después, se incorporan la imputación por la moda de `Embarked`, la transformación de la columna `Cabin`, la creación de la columna `Title` y la imputación con KNN de la columna `Age`. 

Random forest no requiere preprocesamiento exhaustivo sobre los datos de entrenamiento, tales como transformaciones matemáticas (logaritmo de `Fare` o z-score de `Age`) y creación de variables dummy. Además, cabe destacar que `bake()` aplica las transformaciones de la receta a nuevos conjuntos de datos; si `new_data = NULL` entonces retorna los datos de entrenamientos transformados; si `new_data = titanic_test`, se aplican las transformaciones **calculadas sobre el conjunto de entrenamiento** para retornar el conjunto de prueba transformado, evitando así data leakage. 

```{r}
set.seed(123)
titanic_split <- initial_split(titanic_train, strata = Survived)
titanic_train <- training(titanic_split)
titanic_val <- testing(titanic_split)

rf_recipe <- 
  recipe(~ ., data = titanic_train) %>% 
  step_impute_mode(Embarked) %>% 
  step_mutate(Cabin = if_else(is.na(Cabin), "Yes", "No"),
              Title = extract_title(Name)) %>% 
  step_impute_knn(Age, impute_with = c("Title", "Sex", "SibSp", "Parch")) %>% 
  step_impute_knn(Fare, impute_with = c("Age", "Sex", "Embarked", "Pclass"))

prep_recipe <- prep(rf_recipe)  
train_processed <- bake(prep_recipe, new_data = NULL)
val_processed <- bake(prep_recipe, new_data = titanic_val %>%
                         mutate(across(where(is.character), as.factor)))
test_processed <- bake(prep_recipe, new_data = titanic_test %>%
                         mutate(across(where(is.character), as.factor)))
```

### Resampling y afinación de hiperparámetros

Debido a que el dataset es pequeño como para crear un conjunto de validación que sirva para la estimación del desempeño del modelo, se utilizará el método de *10-fold cross validation*.

```{r}
set.seed(123)
titanic_folds <- vfold_cv(train_processed, v = 10)
```

Los errores de entrenamiento y validación serán calculados para cada uno de los subconjuntos en `titanic_folds`, estimando el error de validación como la media de los 10 errores de validación parciales.

Paralelamente, se declara la especificación del modelo de ranfom forests utilizando engine del paquete `ranger`, en *modo clasificación*. Los hiperparámetros a afinar se definen a continuación:

- **mtry**: un entero para el número de predictores que son muestreados aleatoriamente en cada separación al crear los modelos de árbol.

- **min_n**: un entero para el número mínimo de puntos necesarios en un nodo para que pueda seguir dividiéndose.

- **trees**: un entero para el número de árboles contenidos en el ensamblaje.

```{r}
rf_spec <- 
  rand_forest(
    mtry = tune(),
    min_n = tune(),
    trees = tune()
  ) %>% 
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")
```

Se elige usar un método de búsqueda en grilla para optimizar la combinación de hiperparámetros. El diseño de grilla escogido es de hipercubo. Debido a que el hiperparámetro mtry depende de las dimensiones del dataset, el framework de tidymodels requiere que se finalice el parámetro con el rango de dimensiones correctas (entre 1 y 10 porque hay 10 variables: 1 objetivo y 9 predictoras).

```{r}
set.seed(123)
rf_grid <- 
  grid_latin_hypercube(
    rf_spec %>% 
      parameters() %>% 
      update(mtry = range_set(mtry(), c(1, 9)),
             trees = range_set(trees(), c(200, 2000))),
    size = 200
  )
```

Una vez se tienen los componentes más importantes del framework de tidymodels (preprocesamiento, especificación de modelo, resampling y mecanismo de afinación de hiperparámetros), se procede a crear un workflow que los haga interactuar.

```{r}
rf_formula <- formula(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Cabin + Embarked + Title)
rf_wf <- 
  workflow() %>% 
  add_model(rf_spec) %>% 
  add_formula(rf_formula)
```

Afinar 200 combinaciones de hiperparámetros en 10 subconjuntos de datos implica ajustar 2000 veces el modelo de random forest, con una cantidad de árboles que varía entre 200 y 2000. Para acelerar los cálculos, se permite que tidymodels acceda a los múltiples cores que tiene el computador mediante computación paralela, con `doParallel`.

```{r eval=FALSE}
doParallel::registerDoParallel()
set.seed(123)
rf_res <- tune_grid(
  rf_wf,
  resamples = titanic_folds,
  grid = rf_grid,
  control = control_resamples(save_pred = TRUE)
)
```

```{r echo=FALSE, eval=FALSE}
write_rds(rf_res, file = here("Machine Learning Avanzado", "rf_res_titanic.rds"))
```

```{r echo=FALSE}
rf_res <- read_rds(file = here("Machine Learning Avanzado", "rf_res_titanic.rds"))
```

La combinación de hiperparámetros que optimiza accuracy resultó ser trees: 799, mtry: 4 y min_n: 22. Esta combinación alcanzó un accuracy estimado de 0.846, con un error estándar estimado de 0.0169. Paralelamente, el área media bajo la curva ROC estimada es 0.889, con error estándar de 0.0156.

```{r echo=FALSE, fig.width=11}
collect_metrics(rf_res) %>% 
  filter(.metric == "accuracy") %>% 
  pivot_longer(mtry:min_n) %>% 
  group_by(name) %>% 
  mutate(best = ifelse(mean == max(mean), "best", "not best")) %>% 
  ungroup() %>% 
  ggplot(aes(value, mean, color = name, size = mean)) +
  geom_point(show.legend = FALSE, alpha = .5) +
  geom_smooth(show.legend = FALSE, method = "loess", formula = y ~ x) +
  scale_color_manual(values = c("#a92759", "#354fa9", "#018666")) +
  facet_wrap(~name, scales = "free_x") +
  labs(title = "Ajuste de hiperparámetros con validación cruzada",
       x = "Valor del hiperparámetro", y = "Exactitud media de clasificación") 
```

```{r echo=FALSE}
collect_predictions(rf_res) %>% 
  group_by(.config) %>%  
  roc_curve(Survived, .pred_0) %>% 
  ggplot(aes(1 - specificity, sensitivity)) +
  geom_line(show.legend = FALSE, alpha = .7, size = .4, aes(group = .config), color = "gray50") +
  stat_summary(geom = "line", fun = mean, color = "#a92759", size = 1) +
  geom_abline(linetype = 2) +
  annotate(geom = "text", x = .45, y = .35, size = 4.5, family = "Noto Sans", fontface = "italic",
           label = "ROC AUC media = 0.889\nStd. Error = 0.0156", hjust = 0) +
  coord_fixed() +
  labs(title = "Curva ROC del ajuste de hiperparámetros") +
  theme(plot.margin = unit(c(.5,3.3,.5,3.3), "cm"))
```

Sin embargo, prevalece la pregunta: para obtener el mejor conjunto de hiperparámetros ¿conviene optimizar accuracy o el área bajo la curva ROC? Para descubrir qué métrica conviene utilizar, se ajustan dos modelos de random forest, con las configuraciones óptimas de hiperparámetros para accuracy y área bajo la curva ROC, respectivamente.

```{r}
best_accuracy <- select_best(rf_res, metric = "accuracy")
best_roc <- select_best(rf_res, metric = "roc_auc")
final_wf_accuracy <- rf_wf %>% update_model(finalize_model(rf_spec, best_accuracy))
final_wf_roc <- rf_wf %>% update_model(finalize_model(rf_spec, best_roc))
set.seed(123)
rf_fit_accuracy <- fit(final_wf_accuracy, data = train_processed)
set.seed(123)
rf_fit_roc <- fit(final_wf_roc, data = train_processed)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.width=9, fig.height=6}
bind_rows(train = train_processed, validation = val_processed, .id = "set") %>% 
  nest(data = all_of(2:ncol(.))) %>% 
  mutate(pred_accuracy = map(data, ~predict(rf_fit_accuracy, new_data = .x)),
         pred_roc = map(data, ~predict(rf_fit_roc, new_data = .x))) %>% 
  unnest(cols = c(data, pred_accuracy, pred_roc), names_repair = "universal") %>% 
  rename("Best Accuracy" = .pred_class...15, "Best ROC AUC" = .pred_class...16) %>%
  pivot_longer(cols = starts_with("Best"), names_to = "metric", values_to = ".pred_class") %>% 
  relocate(set, metric) %>% 
  nest(data = all_of(3:ncol(.))) %>% 
  mutate(accuracy = map(data, ~accuracy(.x, Survived, .pred_class)),
         accuracy = map_dbl(accuracy, ".estimate"),
         sensitivity = map(data, ~sens(.x, Survived, .pred_class, event_level = "second")),
         sensitivity = map_dbl(sensitivity, ".estimate"),
         specificity = map(data, ~spec(.x, Survived, .pred_class, event_level = "second")),
         specificity = map_dbl(specificity, ".estimate")) %>%  
  pivot_longer(cols = accuracy:specificity) %>% 
  ggplot(aes(set, value, color = name, group = name)) +
  geom_line(size = 1) +
  geom_label(aes(label = round(value, 3)), size = 5, fontface = "bold", label.size = 1) +
  scale_color_manual(values = c("#a92759", "#354fa9", "#018666")) +
  coord_cartesian(ylim = c(.7, 1)) +
  facet_wrap(~metric) +
  theme(legend.position = "none") +
  labs(x = "Set", y = "Valor de la métrica", 
       title = "¿Optimizar Accuracy o ROC AUC?",
       subtitle = "Comparación entre <b style='color:#018666;'>specificity</b>, <b style='color:#a92759;'>accuracy</b> y <b style='color:#354fa9;'>sensitivity</b>") 
```

Se observa que ambos modelos tienden a sobreajustarse. La configuración para el mejor accuracy sobreajusta menos que la configuración con mejor ROC AUC, porque la diferencia entre las métricas de desempeño calculadas en los conjuntos de entrenamiento y validación es menor. Por lo tanto, se escoge la configuración del mejor accuracy para realizar las predicciones sobre el conjunto de prueba.

### Análisis de los resultados 

En el gráfico anterior se aprecia que el mejor modelo (**Best Accuracy**) tiene buen desempeño cuando clasifica pasajeros que no sobrevivieron (specificity), pero empeora al clasificar pasajeros que sobrevivieron (sensitivity). Esto puede deberse al desbalance que existe entre las clases 0 y 1 del factor `Survived` en el conjunto de entrenamiento, que es 62% contra 38%, respectivamente. La manera común de palear este desbalance es usando técnicas de muestreo con reemplazo de la clase minoritaria (*upsampling*) o muestreo de la clase mayoritaria, con tamaño muestral igual a la clase minoritaria (*downsampling*). En este documento se mantendrá el modelo tal cual está.

A continuación, se analiza la importancia de las variables para la predicción de supervivencia de los pasajeros.

```{r echo=FALSE, fig.width=9}
vip::vi(rf_fit_accuracy$fit$fit) %>% 
  mutate(Variable = fct_reorder(Variable, Importance)) %>% 
  ggplot(aes(Importance, Variable)) +
  geom_col(fill = "#012626", alpha = .7) +
  labs(y = NULL, x = "Importancia", 
       title = "¿Cuáles son las variables más importantes para el modelo?")
```

De acuerdo al gráfico, `Sex` es la variable más importante. Esta importancia se calcula al momento de la construcción de los árboles del modelo, midiendo el desempeño de cada árbol en el conjunto *Out Of Bag* del bosque, pero alterando cada variable individual para el cómputo del error. De esta manera, las variables cuya perturbación produzca un mayor efecto en los errores, serán más importantes. Esta importancia se promedia entre todos los árboles del bosque.

```{r}
train_processed %>% count(Sex, Survived) 
```

De acuerdo con los datos de entrenamiento preprocesados, se puede calcular la probabilidad de que una pasajera sobreviva al accidente como la probabilidad condicional sobre la frecuencias observadas de ser mujer y haber sobrevivido. Sea $A:P(Survived=1)$ y $B:P(Sex=female)$

$$
P(A\;|\;B) = \frac{P(A \; \bigcap \; B)}{P(B)} = \frac{176}{59 + 176} \approx 0.75.
$$

Así, la probabilidad de que una pasajero sobreviva, dado que es mujer, es del 75%. Análogamente, se puede calcular la probabilidad de sobrevivir dado que el pasajero es hombre.

$$
P(A \; | \; B^c) = \frac{P(A \; \bigcap \; B^c)}{P(B^c)} = \frac{80}{352 + 80} \approx 0.19.
$$

Se observa que la probabilidad de que un pasajero hombre sobreviva es del 19%. Así, el modelo puede alcanzar una exactitud del 75% prediciendo que el pasajero sobrevive cuando es mujer, y 81% prediciendo que el pasajero no sobrevive cuando éste es hombre.

El mismo análisis puede llevarse a cabo con `Title`, al calcular la probabilidad condicional de supervivencia dado que el pasajero tiene un título determinado. 

```{r}
train_processed %>% 
  count(Title, Survived) %>% 
  group_by(Title) %>% 
  add_count(wt = n, name = "total_n") %>% 
  ungroup() %>% 
  filter(Survived == 1) %>% 
  mutate(B_prob = total_n / sum(total_n),
         joint_prob = n / sum(total_n),
         conditional_prob = joint_prob / B_prob) %>% 
  select(Title, conditional_prob) %>% 
  pivot_wider(names_from = Title, values_from = conditional_prob) 
```

Evidentemente, los pasajeros con título Miss y Mrs, todas mujeres, tienen alta probabilidad de sobrevivir. Es interesante observar que los pasajeros de título Master (niños de hasta 12 años) tienen una probabilidad mucho más alta de sobrevivir respecto de los varones con más de 12 años.

Posteriormente, se analizan las distribuciones de `Fare` y `Age` para ver cómo influyen en la supervivencia de los pasajeros. 

```{r echo=FALSE, fig.width=9}
train_processed %>% 
  select(Fare, Age, Survived) %>% 
  pivot_longer(-Survived) %>% 
  ggplot(aes(value, fill = Survived)) +
  geom_density(show.legend = FALSE, alpha = .4) +
  scale_fill_manual(values = c("#a92759", "#018666")) +
  facet_wrap(~name, scales = "free_x") +
  labs(title = "Conjunto de entrenamiento: distribución de <i>Age</i> y <i>Fare</i>",
       subtitle = "Pasajeros que <b style='color:#018666;'>sobrevivieron</b> o <b style='color:#a92759;'>no sobrevivieron</b>",
       x = NULL, y = "Densidad")
```

La distribución observada de `Age` según supervivencia es multimodal, centrada en torno a los 35 años. Por otra parte, la distribución de `Fare` para los pasajeros que sobreviveron presenta gran asimetría positiva, indicando que pagaron en general más por su ticket que aquellos que no sobrevivieron, cuya distribución se centra en torno a tickets más baratos. 

Respecto a lo anterior cabe preguntarse, ¿qué distribuciones ha asumido el modelo para predecir supervivencia?

```{r echo=FALSE, fig.width=9}
bind_cols(val_processed, predict(rf_fit_accuracy, val_processed)) %>% 
  select(Fare, Age, .pred_class) %>% 
  pivot_longer(-.pred_class) %>% 
  ggplot(aes(value, fill = .pred_class)) +
  geom_density(show.legend = FALSE, alpha = .4) +
  scale_fill_manual(values = c("#a92759", "#018666")) +
  facet_wrap(~name, scales = "free_x") +
  labs(title = "Conjunto de validación: <i>Age</i> y <i>Fare</i>", 
       subtitle = "Predicción de pasajeros que <b style='color:#018666;'>sobrevivieron</b> o <b style='color:#a92759;'>no sobrevivieron</b>",
       x = NULL, y = "Densidad")
```

Interesantemente, ambas variables son menos asimétricas que en el conjunto de entrenamiento, pero sigue existiendo gran solapamiento entre las clases de supervivencia. Queda claro que el modelo aprendió que los pasajeros sobre 60 años tuvieron menos chances de sobrevivir. Al contrario, aquellos pasajeros que pagaron altas tarifas probablemente sobrevivieron.















